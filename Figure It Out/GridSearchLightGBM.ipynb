{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import sklearn\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset():\n",
    "    train = pd.read_csv(\"./train/train.csv\")\n",
    "    test = pd.read_csv(\"./test/test.csv\")\n",
    "    features = [f for f in test.columns if \"x_\" in f]\n",
    "    x = train[features]\n",
    "    y = train[\"targets\"]\n",
    "    x_test = test[features]\n",
    "    return x,y,x_test,test\n",
    "\n",
    "def sub(a):\n",
    "    return a-1\n",
    "\n",
    "def maipulate_Dataset(y):\n",
    "    y_n = y.apply(sub)\n",
    "    return y_n\n",
    "    \n",
    "def light_GBM_D(x,y):\n",
    "    d_train = lgb.Dataset(x,label=y)\n",
    "    return d_train\n",
    "    \n",
    "def filesub(v,y_pred,test):\n",
    "    a = pd.DataFrame(y_pred,columns=['proba_1', 'proba_2', 'proba_3', 'proba_4', 'proba_5', 'proba_6', 'proba_7', 'proba_8', 'proba_9'])\n",
    "    a[\"unique_id\"] = test[\"unique_id\"]\n",
    "    columns=[\"unique_id\",'proba_1', 'proba_2', 'proba_3', 'proba_4', 'proba_5', 'proba_6', 'proba_7', 'proba_8', 'proba_9']\n",
    "    a = a[columns]\n",
    "    a.to_csv(v+\"_sub.csv\",index=False)\n",
    "\n",
    "def val_data_split(x,y):\n",
    "    x_train,x_val,y_train,y_val = train_test_split(x,y,test_size=0.10,random_state=42)\n",
    "    return x_train,x_val,y_train,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling and manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,x_test,test = dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_val,y_train,y_val = val_data_split(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_n = maipulate_Dataset(y_train)\n",
    "y_v = maipulate_Dataset(y_val)\n",
    "\n",
    "d_train = light_GBM_D(x_train,y_n)\n",
    "d_val = light_GBM_D(x_val,y_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameters to search\n",
    "gridParams = {\n",
    "    'learning_rate': [0.005,0.01],\n",
    "    'num_leaves': [6,8,12,16,32,64,128],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['multiclass'],\n",
    "    'max_bin':[256,512],\n",
    "    'n_estimators':[10,40,100],\n",
    "    'max_depth':[7,8,9]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = lgb.LGBMClassifier(objective = params['objective'],silent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(mdl, gridParams,\n",
    "                    verbose=1,\n",
    "                    cv=3,\n",
    "                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 252 candidates, totalling 756 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 17.8min\n",
      "[Parallel(n_jobs=-1)]: Done 756 out of 756 | elapsed: 32.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_leaves=31, objective='multiclass',\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=False,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'learning_rate': [0.005, 0.01], 'num_leaves': [6, 8, 12, 16, 32, 64, 128], 'boosting_type': ['gbdt'], 'objective': ['multiclass'], 'max_bin': [256, 512], 'n_estimators': [10, 40, 100], 'max_depth': [7, 8, 9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'gbdt', 'learning_rate': 0.01, 'max_bin': 256, 'max_depth': 9, 'n_estimators': 100, 'num_leaves': 128, 'objective': 'multiclass'}\n",
      "0.7417802503477051\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional params\n",
    "v['metric'] = \"multi_logloss\"\n",
    "v['num_classes'] = 9\n",
    "v['n_estimators'] = 10000\n",
    "v['num_leaves'] = 80\n",
    "v['learning_rate'] = 0.01\n",
    "v['boosting_type'] = 'dart'\n",
    "params['sub_feature'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'dart',\n",
       " 'learning_rate': 0.01,\n",
       " 'max_depth': 9,\n",
       " 'n_estimators': 10000,\n",
       " 'num_leaves': 80,\n",
       " 'objective': 'multiclass',\n",
       " 'metric': 'multi_logloss',\n",
       " 'num_classes': 9}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's multi_logloss: 1.7797\teval's multi_logloss: 1.77989\n",
      "[20]\ttrain's multi_logloss: 1.64686\teval's multi_logloss: 1.66173\n",
      "[30]\ttrain's multi_logloss: 1.55369\teval's multi_logloss: 1.57808\n",
      "[40]\ttrain's multi_logloss: 1.49966\teval's multi_logloss: 1.52918\n",
      "[50]\ttrain's multi_logloss: 1.49739\teval's multi_logloss: 1.52917\n",
      "[60]\ttrain's multi_logloss: 1.47512\teval's multi_logloss: 1.51148\n",
      "[70]\ttrain's multi_logloss: 1.46609\teval's multi_logloss: 1.50575\n",
      "[80]\ttrain's multi_logloss: 1.43707\teval's multi_logloss: 1.47881\n",
      "[90]\ttrain's multi_logloss: 1.44714\teval's multi_logloss: 1.48737\n",
      "[100]\ttrain's multi_logloss: 1.43804\teval's multi_logloss: 1.48143\n",
      "[110]\ttrain's multi_logloss: 1.47546\teval's multi_logloss: 1.51749\n",
      "[120]\ttrain's multi_logloss: 1.42217\teval's multi_logloss: 1.46842\n",
      "[130]\ttrain's multi_logloss: 1.4\teval's multi_logloss: 1.44769\n",
      "[140]\ttrain's multi_logloss: 1.39628\teval's multi_logloss: 1.44647\n",
      "[150]\ttrain's multi_logloss: 1.38894\teval's multi_logloss: 1.43938\n",
      "[160]\ttrain's multi_logloss: 1.4169\teval's multi_logloss: 1.46613\n",
      "[170]\ttrain's multi_logloss: 1.35969\teval's multi_logloss: 1.41413\n",
      "[180]\ttrain's multi_logloss: 1.34369\teval's multi_logloss: 1.39955\n",
      "[190]\ttrain's multi_logloss: 1.30366\teval's multi_logloss: 1.36226\n",
      "[200]\ttrain's multi_logloss: 1.28689\teval's multi_logloss: 1.34661\n",
      "[210]\ttrain's multi_logloss: 1.29801\teval's multi_logloss: 1.35711\n",
      "[220]\ttrain's multi_logloss: 1.26199\teval's multi_logloss: 1.32427\n",
      "[230]\ttrain's multi_logloss: 1.25799\teval's multi_logloss: 1.32052\n",
      "[240]\ttrain's multi_logloss: 1.21058\teval's multi_logloss: 1.27725\n",
      "[250]\ttrain's multi_logloss: 1.20156\teval's multi_logloss: 1.26938\n",
      "[260]\ttrain's multi_logloss: 1.17927\teval's multi_logloss: 1.249\n",
      "[270]\ttrain's multi_logloss: 1.14845\teval's multi_logloss: 1.22101\n",
      "[280]\ttrain's multi_logloss: 1.13835\teval's multi_logloss: 1.21195\n",
      "[290]\ttrain's multi_logloss: 1.11174\teval's multi_logloss: 1.1884\n",
      "[300]\ttrain's multi_logloss: 1.11219\teval's multi_logloss: 1.18885\n",
      "[310]\ttrain's multi_logloss: 1.12178\teval's multi_logloss: 1.19769\n",
      "[320]\ttrain's multi_logloss: 1.09502\teval's multi_logloss: 1.17398\n",
      "[330]\ttrain's multi_logloss: 1.08525\teval's multi_logloss: 1.1653\n",
      "[340]\ttrain's multi_logloss: 1.09449\teval's multi_logloss: 1.1739\n",
      "[350]\ttrain's multi_logloss: 1.06807\teval's multi_logloss: 1.15015\n",
      "[360]\ttrain's multi_logloss: 1.05213\teval's multi_logloss: 1.13586\n",
      "[370]\ttrain's multi_logloss: 1.04319\teval's multi_logloss: 1.12785\n",
      "[380]\ttrain's multi_logloss: 1.02697\teval's multi_logloss: 1.11333\n",
      "[390]\ttrain's multi_logloss: 1.00424\teval's multi_logloss: 1.09301\n",
      "[400]\ttrain's multi_logloss: 0.97533\teval's multi_logloss: 1.06711\n",
      "[410]\ttrain's multi_logloss: 0.96272\teval's multi_logloss: 1.05607\n",
      "[420]\ttrain's multi_logloss: 0.956899\teval's multi_logloss: 1.05101\n",
      "[430]\ttrain's multi_logloss: 0.938869\teval's multi_logloss: 1.03517\n",
      "[440]\ttrain's multi_logloss: 0.927268\teval's multi_logloss: 1.025\n",
      "[450]\ttrain's multi_logloss: 0.902838\teval's multi_logloss: 1.00338\n",
      "[460]\ttrain's multi_logloss: 0.904706\teval's multi_logloss: 1.00518\n",
      "[470]\ttrain's multi_logloss: 0.900335\teval's multi_logloss: 1.00152\n",
      "[480]\ttrain's multi_logloss: 0.889056\teval's multi_logloss: 0.991458\n",
      "[490]\ttrain's multi_logloss: 0.866977\teval's multi_logloss: 0.971832\n",
      "[500]\ttrain's multi_logloss: 0.856523\teval's multi_logloss: 0.962509\n",
      "[510]\ttrain's multi_logloss: 0.841224\teval's multi_logloss: 0.948918\n",
      "[520]\ttrain's multi_logloss: 0.836747\teval's multi_logloss: 0.945074\n",
      "[530]\ttrain's multi_logloss: 0.832987\teval's multi_logloss: 0.941951\n",
      "[540]\ttrain's multi_logloss: 0.828426\teval's multi_logloss: 0.93803\n",
      "[550]\ttrain's multi_logloss: 0.819212\teval's multi_logloss: 0.929966\n",
      "[560]\ttrain's multi_logloss: 0.810325\teval's multi_logloss: 0.922229\n",
      "[570]\ttrain's multi_logloss: 0.815295\teval's multi_logloss: 0.92662\n",
      "[580]\ttrain's multi_logloss: 0.820208\teval's multi_logloss: 0.93093\n",
      "[590]\ttrain's multi_logloss: 0.81979\teval's multi_logloss: 0.930615\n",
      "[600]\ttrain's multi_logloss: 0.819336\teval's multi_logloss: 0.930161\n",
      "[610]\ttrain's multi_logloss: 0.813862\teval's multi_logloss: 0.925519\n",
      "[620]\ttrain's multi_logloss: 0.795153\teval's multi_logloss: 0.909255\n",
      "[630]\ttrain's multi_logloss: 0.790739\teval's multi_logloss: 0.90551\n",
      "[640]\ttrain's multi_logloss: 0.781831\teval's multi_logloss: 0.897797\n",
      "[650]\ttrain's multi_logloss: 0.777409\teval's multi_logloss: 0.894159\n",
      "[660]\ttrain's multi_logloss: 0.77255\teval's multi_logloss: 0.889921\n",
      "[670]\ttrain's multi_logloss: 0.776347\teval's multi_logloss: 0.893415\n",
      "[680]\ttrain's multi_logloss: 0.763522\teval's multi_logloss: 0.882516\n",
      "[690]\ttrain's multi_logloss: 0.759411\teval's multi_logloss: 0.879067\n",
      "[700]\ttrain's multi_logloss: 0.750916\teval's multi_logloss: 0.871761\n",
      "[710]\ttrain's multi_logloss: 0.745995\teval's multi_logloss: 0.867604\n",
      "[720]\ttrain's multi_logloss: 0.749607\teval's multi_logloss: 0.870874\n",
      "[730]\ttrain's multi_logloss: 0.738101\teval's multi_logloss: 0.861152\n",
      "[740]\ttrain's multi_logloss: 0.733476\teval's multi_logloss: 0.857127\n",
      "[750]\ttrain's multi_logloss: 0.72555\teval's multi_logloss: 0.850423\n",
      "[760]\ttrain's multi_logloss: 0.72123\teval's multi_logloss: 0.846775\n",
      "[770]\ttrain's multi_logloss: 0.716812\teval's multi_logloss: 0.843138\n",
      "[780]\ttrain's multi_logloss: 0.715386\teval's multi_logloss: 0.842009\n",
      "[790]\ttrain's multi_logloss: 0.711596\teval's multi_logloss: 0.838873\n",
      "[800]\ttrain's multi_logloss: 0.710416\teval's multi_logloss: 0.837971\n",
      "[810]\ttrain's multi_logloss: 0.708586\teval's multi_logloss: 0.836484\n",
      "[820]\ttrain's multi_logloss: 0.703942\teval's multi_logloss: 0.832615\n",
      "[830]\ttrain's multi_logloss: 0.693083\teval's multi_logloss: 0.823309\n",
      "[840]\ttrain's multi_logloss: 0.682613\teval's multi_logloss: 0.81445\n",
      "[850]\ttrain's multi_logloss: 0.678349\teval's multi_logloss: 0.811\n",
      "[860]\ttrain's multi_logloss: 0.673964\teval's multi_logloss: 0.807525\n",
      "[870]\ttrain's multi_logloss: 0.667043\teval's multi_logloss: 0.801865\n",
      "[880]\ttrain's multi_logloss: 0.669055\teval's multi_logloss: 0.803734\n",
      "[890]\ttrain's multi_logloss: 0.659509\teval's multi_logloss: 0.795831\n",
      "[900]\ttrain's multi_logloss: 0.655665\teval's multi_logloss: 0.792895\n",
      "[910]\ttrain's multi_logloss: 0.654666\teval's multi_logloss: 0.79217\n",
      "[920]\ttrain's multi_logloss: 0.656052\teval's multi_logloss: 0.793434\n",
      "[930]\ttrain's multi_logloss: 0.651826\teval's multi_logloss: 0.790142\n",
      "[940]\ttrain's multi_logloss: 0.647968\teval's multi_logloss: 0.786962\n",
      "[950]\ttrain's multi_logloss: 0.641724\teval's multi_logloss: 0.781904\n",
      "[960]\ttrain's multi_logloss: 0.635675\teval's multi_logloss: 0.777193\n",
      "[970]\ttrain's multi_logloss: 0.631904\teval's multi_logloss: 0.77425\n",
      "[980]\ttrain's multi_logloss: 0.62851\teval's multi_logloss: 0.771593\n",
      "[990]\ttrain's multi_logloss: 0.629434\teval's multi_logloss: 0.772484\n",
      "[1000]\ttrain's multi_logloss: 0.623191\teval's multi_logloss: 0.767389\n",
      "[1010]\ttrain's multi_logloss: 0.614928\teval's multi_logloss: 0.760729\n",
      "[1020]\ttrain's multi_logloss: 0.611488\teval's multi_logloss: 0.758055\n",
      "[1030]\ttrain's multi_logloss: 0.60816\teval's multi_logloss: 0.755393\n",
      "[1040]\ttrain's multi_logloss: 0.604689\teval's multi_logloss: 0.7526\n",
      "[1050]\ttrain's multi_logloss: 0.599313\teval's multi_logloss: 0.748453\n",
      "[1060]\ttrain's multi_logloss: 0.60009\teval's multi_logloss: 0.749224\n",
      "[1070]\ttrain's multi_logloss: 0.598454\teval's multi_logloss: 0.748062\n",
      "[1080]\ttrain's multi_logloss: 0.5953\teval's multi_logloss: 0.745584\n",
      "[1090]\ttrain's multi_logloss: 0.59442\teval's multi_logloss: 0.745048\n",
      "[1100]\ttrain's multi_logloss: 0.587256\teval's multi_logloss: 0.739477\n",
      "[1110]\ttrain's multi_logloss: 0.589909\teval's multi_logloss: 0.741728\n",
      "[1120]\ttrain's multi_logloss: 0.59454\teval's multi_logloss: 0.745602\n",
      "[1130]\ttrain's multi_logloss: 0.586927\teval's multi_logloss: 0.739593\n",
      "[1140]\ttrain's multi_logloss: 0.583463\teval's multi_logloss: 0.736942\n",
      "[1150]\ttrain's multi_logloss: 0.580228\teval's multi_logloss: 0.734495\n",
      "[1160]\ttrain's multi_logloss: 0.578849\teval's multi_logloss: 0.733458\n",
      "[1170]\ttrain's multi_logloss: 0.578037\teval's multi_logloss: 0.73301\n",
      "[1180]\ttrain's multi_logloss: 0.576854\teval's multi_logloss: 0.732261\n",
      "[1190]\ttrain's multi_logloss: 0.571915\teval's multi_logloss: 0.728358\n",
      "[1200]\ttrain's multi_logloss: 0.569116\teval's multi_logloss: 0.726241\n",
      "[1210]\ttrain's multi_logloss: 0.560444\teval's multi_logloss: 0.71958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1220]\ttrain's multi_logloss: 0.555399\teval's multi_logloss: 0.715677\n",
      "[1230]\ttrain's multi_logloss: 0.552333\teval's multi_logloss: 0.713289\n",
      "[1240]\ttrain's multi_logloss: 0.554463\teval's multi_logloss: 0.715191\n",
      "[1250]\ttrain's multi_logloss: 0.551469\teval's multi_logloss: 0.713142\n",
      "[1260]\ttrain's multi_logloss: 0.548579\teval's multi_logloss: 0.711126\n",
      "[1270]\ttrain's multi_logloss: 0.547466\teval's multi_logloss: 0.710381\n",
      "[1280]\ttrain's multi_logloss: 0.547615\teval's multi_logloss: 0.710684\n",
      "[1290]\ttrain's multi_logloss: 0.549876\teval's multi_logloss: 0.712554\n",
      "[1300]\ttrain's multi_logloss: 0.543364\teval's multi_logloss: 0.707426\n",
      "[1310]\ttrain's multi_logloss: 0.537154\teval's multi_logloss: 0.702875\n",
      "[1320]\ttrain's multi_logloss: 0.537287\teval's multi_logloss: 0.703116\n",
      "[1330]\ttrain's multi_logloss: 0.529792\teval's multi_logloss: 0.697447\n",
      "[1340]\ttrain's multi_logloss: 0.530642\teval's multi_logloss: 0.698225\n",
      "[1350]\ttrain's multi_logloss: 0.531157\teval's multi_logloss: 0.698784\n",
      "[1360]\ttrain's multi_logloss: 0.525479\teval's multi_logloss: 0.694512\n",
      "[1370]\ttrain's multi_logloss: 0.516827\teval's multi_logloss: 0.688092\n",
      "[1380]\ttrain's multi_logloss: 0.514587\teval's multi_logloss: 0.686543\n",
      "[1390]\ttrain's multi_logloss: 0.513418\teval's multi_logloss: 0.685811\n",
      "[1400]\ttrain's multi_logloss: 0.509336\teval's multi_logloss: 0.682751\n",
      "[1410]\ttrain's multi_logloss: 0.508387\teval's multi_logloss: 0.682203\n",
      "[1420]\ttrain's multi_logloss: 0.507264\teval's multi_logloss: 0.681418\n",
      "[1430]\ttrain's multi_logloss: 0.504586\teval's multi_logloss: 0.679484\n",
      "[1440]\ttrain's multi_logloss: 0.504838\teval's multi_logloss: 0.679785\n",
      "[1450]\ttrain's multi_logloss: 0.503558\teval's multi_logloss: 0.679028\n",
      "[1460]\ttrain's multi_logloss: 0.49835\teval's multi_logloss: 0.675152\n",
      "[1470]\ttrain's multi_logloss: 0.497149\teval's multi_logloss: 0.674373\n",
      "[1480]\ttrain's multi_logloss: 0.497236\teval's multi_logloss: 0.674546\n",
      "[1490]\ttrain's multi_logloss: 0.496327\teval's multi_logloss: 0.67397\n",
      "[1500]\ttrain's multi_logloss: 0.496118\teval's multi_logloss: 0.673941\n",
      "[1510]\ttrain's multi_logloss: 0.497527\teval's multi_logloss: 0.675124\n",
      "[1520]\ttrain's multi_logloss: 0.496496\teval's multi_logloss: 0.67458\n",
      "[1530]\ttrain's multi_logloss: 0.495004\teval's multi_logloss: 0.673579\n",
      "[1540]\ttrain's multi_logloss: 0.492557\teval's multi_logloss: 0.671759\n",
      "[1550]\ttrain's multi_logloss: 0.488925\teval's multi_logloss: 0.669194\n",
      "[1560]\ttrain's multi_logloss: 0.486511\teval's multi_logloss: 0.667547\n",
      "[1570]\ttrain's multi_logloss: 0.482979\teval's multi_logloss: 0.665128\n",
      "[1580]\ttrain's multi_logloss: 0.47688\teval's multi_logloss: 0.66082\n",
      "[1590]\ttrain's multi_logloss: 0.473254\teval's multi_logloss: 0.658367\n",
      "[1600]\ttrain's multi_logloss: 0.470891\teval's multi_logloss: 0.6569\n",
      "[1610]\ttrain's multi_logloss: 0.468775\teval's multi_logloss: 0.655477\n",
      "[1620]\ttrain's multi_logloss: 0.468728\teval's multi_logloss: 0.655627\n",
      "[1630]\ttrain's multi_logloss: 0.464175\teval's multi_logloss: 0.652623\n",
      "[1640]\ttrain's multi_logloss: 0.461911\teval's multi_logloss: 0.651198\n",
      "[1650]\ttrain's multi_logloss: 0.464327\teval's multi_logloss: 0.653076\n",
      "[1660]\ttrain's multi_logloss: 0.460053\teval's multi_logloss: 0.65024\n",
      "[1670]\ttrain's multi_logloss: 0.458037\teval's multi_logloss: 0.648935\n",
      "[1680]\ttrain's multi_logloss: 0.453593\teval's multi_logloss: 0.646001\n",
      "[1690]\ttrain's multi_logloss: 0.45047\teval's multi_logloss: 0.643993\n",
      "[1700]\ttrain's multi_logloss: 0.447588\teval's multi_logloss: 0.64216\n",
      "[1710]\ttrain's multi_logloss: 0.445471\teval's multi_logloss: 0.640845\n",
      "[1720]\ttrain's multi_logloss: 0.444552\teval's multi_logloss: 0.640367\n",
      "[1730]\ttrain's multi_logloss: 0.441757\teval's multi_logloss: 0.638523\n",
      "[1740]\ttrain's multi_logloss: 0.440817\teval's multi_logloss: 0.638002\n",
      "[1750]\ttrain's multi_logloss: 0.437984\teval's multi_logloss: 0.636205\n",
      "[1760]\ttrain's multi_logloss: 0.436044\teval's multi_logloss: 0.635073\n",
      "[1770]\ttrain's multi_logloss: 0.434144\teval's multi_logloss: 0.633899\n",
      "[1780]\ttrain's multi_logloss: 0.432332\teval's multi_logloss: 0.632838\n",
      "[1790]\ttrain's multi_logloss: 0.429626\teval's multi_logloss: 0.631209\n",
      "[1800]\ttrain's multi_logloss: 0.429726\teval's multi_logloss: 0.631474\n",
      "[1810]\ttrain's multi_logloss: 0.425132\teval's multi_logloss: 0.628536\n",
      "[1820]\ttrain's multi_logloss: 0.422429\teval's multi_logloss: 0.626929\n",
      "[1830]\ttrain's multi_logloss: 0.422445\teval's multi_logloss: 0.627107\n",
      "[1840]\ttrain's multi_logloss: 0.420715\teval's multi_logloss: 0.626196\n",
      "[1850]\ttrain's multi_logloss: 0.419039\teval's multi_logloss: 0.625138\n",
      "[1860]\ttrain's multi_logloss: 0.418987\teval's multi_logloss: 0.625258\n",
      "[1870]\ttrain's multi_logloss: 0.416299\teval's multi_logloss: 0.623567\n",
      "[1880]\ttrain's multi_logloss: 0.415605\teval's multi_logloss: 0.623258\n",
      "[1890]\ttrain's multi_logloss: 0.41576\teval's multi_logloss: 0.623497\n",
      "[1900]\ttrain's multi_logloss: 0.41154\teval's multi_logloss: 0.620716\n",
      "[1910]\ttrain's multi_logloss: 0.411603\teval's multi_logloss: 0.620911\n",
      "[1920]\ttrain's multi_logloss: 0.41239\teval's multi_logloss: 0.621538\n",
      "[1930]\ttrain's multi_logloss: 0.411429\teval's multi_logloss: 0.620969\n",
      "[1940]\ttrain's multi_logloss: 0.407994\teval's multi_logloss: 0.618768\n",
      "[1950]\ttrain's multi_logloss: 0.404806\teval's multi_logloss: 0.616801\n",
      "[1960]\ttrain's multi_logloss: 0.404761\teval's multi_logloss: 0.616875\n",
      "[1970]\ttrain's multi_logloss: 0.403056\teval's multi_logloss: 0.615915\n",
      "[1980]\ttrain's multi_logloss: 0.401325\teval's multi_logloss: 0.614933\n",
      "[1990]\ttrain's multi_logloss: 0.401288\teval's multi_logloss: 0.615028\n",
      "[2000]\ttrain's multi_logloss: 0.398164\teval's multi_logloss: 0.613235\n",
      "[2010]\ttrain's multi_logloss: 0.397278\teval's multi_logloss: 0.612823\n",
      "[2020]\ttrain's multi_logloss: 0.392746\teval's multi_logloss: 0.610108\n",
      "[2030]\ttrain's multi_logloss: 0.391171\teval's multi_logloss: 0.609284\n",
      "[2040]\ttrain's multi_logloss: 0.389614\teval's multi_logloss: 0.608448\n",
      "[2050]\ttrain's multi_logloss: 0.388751\teval's multi_logloss: 0.608008\n",
      "[2060]\ttrain's multi_logloss: 0.386528\teval's multi_logloss: 0.606826\n",
      "[2070]\ttrain's multi_logloss: 0.387768\teval's multi_logloss: 0.607721\n",
      "[2080]\ttrain's multi_logloss: 0.384722\teval's multi_logloss: 0.606022\n",
      "[2090]\ttrain's multi_logloss: 0.381664\teval's multi_logloss: 0.604223\n",
      "[2100]\ttrain's multi_logloss: 0.378983\teval's multi_logloss: 0.602636\n",
      "[2110]\ttrain's multi_logloss: 0.379024\teval's multi_logloss: 0.602692\n",
      "[2120]\ttrain's multi_logloss: 0.378338\teval's multi_logloss: 0.602454\n",
      "[2130]\ttrain's multi_logloss: 0.377593\teval's multi_logloss: 0.602208\n",
      "[2140]\ttrain's multi_logloss: 0.376029\teval's multi_logloss: 0.601416\n",
      "[2150]\ttrain's multi_logloss: 0.374531\teval's multi_logloss: 0.600601\n",
      "[2160]\ttrain's multi_logloss: 0.372558\teval's multi_logloss: 0.599551\n",
      "[2170]\ttrain's multi_logloss: 0.371955\teval's multi_logloss: 0.599295\n",
      "[2180]\ttrain's multi_logloss: 0.369296\teval's multi_logloss: 0.597869\n",
      "[2190]\ttrain's multi_logloss: 0.367937\teval's multi_logloss: 0.597147\n",
      "[2200]\ttrain's multi_logloss: 0.365343\teval's multi_logloss: 0.595693\n",
      "[2210]\ttrain's multi_logloss: 0.365744\teval's multi_logloss: 0.596049\n",
      "[2220]\ttrain's multi_logloss: 0.363816\teval's multi_logloss: 0.595061\n",
      "[2230]\ttrain's multi_logloss: 0.36273\teval's multi_logloss: 0.594675\n",
      "[2240]\ttrain's multi_logloss: 0.361389\teval's multi_logloss: 0.593954\n",
      "[2250]\ttrain's multi_logloss: 0.358948\teval's multi_logloss: 0.592659\n",
      "[2260]\ttrain's multi_logloss: 0.355316\teval's multi_logloss: 0.590638\n",
      "[2270]\ttrain's multi_logloss: 0.35475\teval's multi_logloss: 0.590444\n",
      "[2280]\ttrain's multi_logloss: 0.354073\teval's multi_logloss: 0.590135\n",
      "[2290]\ttrain's multi_logloss: 0.351033\teval's multi_logloss: 0.588556\n",
      "[2300]\ttrain's multi_logloss: 0.349763\teval's multi_logloss: 0.58801\n",
      "[2310]\ttrain's multi_logloss: 0.349126\teval's multi_logloss: 0.587719\n",
      "[2320]\ttrain's multi_logloss: 0.347437\teval's multi_logloss: 0.586903\n",
      "[2330]\ttrain's multi_logloss: 0.345684\teval's multi_logloss: 0.58605\n",
      "[2340]\ttrain's multi_logloss: 0.344555\teval's multi_logloss: 0.585516\n",
      "[2350]\ttrain's multi_logloss: 0.342947\teval's multi_logloss: 0.584773\n",
      "[2360]\ttrain's multi_logloss: 0.340286\teval's multi_logloss: 0.58342\n",
      "[2370]\ttrain's multi_logloss: 0.339301\teval's multi_logloss: 0.583008\n",
      "[2380]\ttrain's multi_logloss: 0.337681\teval's multi_logloss: 0.58226\n",
      "[2390]\ttrain's multi_logloss: 0.336076\teval's multi_logloss: 0.581512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2400]\ttrain's multi_logloss: 0.335238\teval's multi_logloss: 0.581109\n",
      "[2410]\ttrain's multi_logloss: 0.334195\teval's multi_logloss: 0.580618\n",
      "[2420]\ttrain's multi_logloss: 0.333091\teval's multi_logloss: 0.580182\n",
      "[2430]\ttrain's multi_logloss: 0.33302\teval's multi_logloss: 0.580213\n",
      "[2440]\ttrain's multi_logloss: 0.331944\teval's multi_logloss: 0.579788\n",
      "[2450]\ttrain's multi_logloss: 0.33093\teval's multi_logloss: 0.579302\n",
      "[2460]\ttrain's multi_logloss: 0.328956\teval's multi_logloss: 0.578404\n",
      "[2470]\ttrain's multi_logloss: 0.327846\teval's multi_logloss: 0.577924\n",
      "[2480]\ttrain's multi_logloss: 0.326442\teval's multi_logloss: 0.577382\n",
      "[2490]\ttrain's multi_logloss: 0.326725\teval's multi_logloss: 0.577597\n",
      "[2500]\ttrain's multi_logloss: 0.325072\teval's multi_logloss: 0.576958\n",
      "[2510]\ttrain's multi_logloss: 0.32314\teval's multi_logloss: 0.576107\n",
      "[2520]\ttrain's multi_logloss: 0.322316\teval's multi_logloss: 0.575794\n",
      "[2530]\ttrain's multi_logloss: 0.321234\teval's multi_logloss: 0.575329\n",
      "[2540]\ttrain's multi_logloss: 0.320675\teval's multi_logloss: 0.575154\n",
      "[2550]\ttrain's multi_logloss: 0.320585\teval's multi_logloss: 0.575237\n",
      "[2560]\ttrain's multi_logloss: 0.319572\teval's multi_logloss: 0.574928\n",
      "[2570]\ttrain's multi_logloss: 0.319036\teval's multi_logloss: 0.57477\n",
      "[2580]\ttrain's multi_logloss: 0.318149\teval's multi_logloss: 0.574541\n",
      "[2590]\ttrain's multi_logloss: 0.317046\teval's multi_logloss: 0.574077\n",
      "[2600]\ttrain's multi_logloss: 0.315653\teval's multi_logloss: 0.573563\n",
      "[2610]\ttrain's multi_logloss: 0.314696\teval's multi_logloss: 0.573216\n",
      "[2620]\ttrain's multi_logloss: 0.314166\teval's multi_logloss: 0.573108\n",
      "[2630]\ttrain's multi_logloss: 0.312695\teval's multi_logloss: 0.57247\n",
      "[2640]\ttrain's multi_logloss: 0.311696\teval's multi_logloss: 0.572137\n",
      "[2650]\ttrain's multi_logloss: 0.311524\teval's multi_logloss: 0.572099\n",
      "[2660]\ttrain's multi_logloss: 0.310069\teval's multi_logloss: 0.571568\n",
      "[2670]\ttrain's multi_logloss: 0.310525\teval's multi_logloss: 0.571857\n",
      "[2680]\ttrain's multi_logloss: 0.309003\teval's multi_logloss: 0.571278\n",
      "[2690]\ttrain's multi_logloss: 0.307579\teval's multi_logloss: 0.570778\n",
      "[2700]\ttrain's multi_logloss: 0.305772\teval's multi_logloss: 0.570078\n",
      "[2710]\ttrain's multi_logloss: 0.30484\teval's multi_logloss: 0.569725\n",
      "[2720]\ttrain's multi_logloss: 0.304712\teval's multi_logloss: 0.569718\n",
      "[2730]\ttrain's multi_logloss: 0.30501\teval's multi_logloss: 0.569917\n",
      "[2740]\ttrain's multi_logloss: 0.304843\teval's multi_logloss: 0.569951\n",
      "[2750]\ttrain's multi_logloss: 0.303699\teval's multi_logloss: 0.569588\n",
      "[2760]\ttrain's multi_logloss: 0.304074\teval's multi_logloss: 0.569773\n",
      "[2770]\ttrain's multi_logloss: 0.303864\teval's multi_logloss: 0.569769\n",
      "[2780]\ttrain's multi_logloss: 0.30237\teval's multi_logloss: 0.569153\n",
      "[2790]\ttrain's multi_logloss: 0.302251\teval's multi_logloss: 0.569233\n",
      "[2800]\ttrain's multi_logloss: 0.300831\teval's multi_logloss: 0.568752\n",
      "[2810]\ttrain's multi_logloss: 0.300352\teval's multi_logloss: 0.568667\n",
      "[2820]\ttrain's multi_logloss: 0.299359\teval's multi_logloss: 0.56831\n",
      "[2830]\ttrain's multi_logloss: 0.298795\teval's multi_logloss: 0.568124\n",
      "[2840]\ttrain's multi_logloss: 0.298235\teval's multi_logloss: 0.567968\n",
      "[2850]\ttrain's multi_logloss: 0.296922\teval's multi_logloss: 0.5675\n",
      "[2860]\ttrain's multi_logloss: 0.295995\teval's multi_logloss: 0.567148\n",
      "[2870]\ttrain's multi_logloss: 0.294593\teval's multi_logloss: 0.56657\n",
      "[2880]\ttrain's multi_logloss: 0.292958\teval's multi_logloss: 0.565906\n",
      "[2890]\ttrain's multi_logloss: 0.291781\teval's multi_logloss: 0.565414\n",
      "[2900]\ttrain's multi_logloss: 0.291267\teval's multi_logloss: 0.565211\n",
      "[2910]\ttrain's multi_logloss: 0.290841\teval's multi_logloss: 0.565142\n",
      "[2920]\ttrain's multi_logloss: 0.289956\teval's multi_logloss: 0.564849\n",
      "[2930]\ttrain's multi_logloss: 0.289144\teval's multi_logloss: 0.564607\n",
      "[2940]\ttrain's multi_logloss: 0.287918\teval's multi_logloss: 0.564102\n",
      "[2950]\ttrain's multi_logloss: 0.287\teval's multi_logloss: 0.563784\n",
      "[2960]\ttrain's multi_logloss: 0.286515\teval's multi_logloss: 0.563612\n",
      "[2970]\ttrain's multi_logloss: 0.284504\teval's multi_logloss: 0.562774\n",
      "[2980]\ttrain's multi_logloss: 0.283396\teval's multi_logloss: 0.562308\n",
      "[2990]\ttrain's multi_logloss: 0.282259\teval's multi_logloss: 0.561852\n",
      "[3000]\ttrain's multi_logloss: 0.281452\teval's multi_logloss: 0.561531\n",
      "[3010]\ttrain's multi_logloss: 0.280993\teval's multi_logloss: 0.561425\n",
      "[3020]\ttrain's multi_logloss: 0.279836\teval's multi_logloss: 0.560941\n",
      "[3030]\ttrain's multi_logloss: 0.279145\teval's multi_logloss: 0.560722\n",
      "[3040]\ttrain's multi_logloss: 0.277943\teval's multi_logloss: 0.560286\n",
      "[3050]\ttrain's multi_logloss: 0.277162\teval's multi_logloss: 0.560051\n",
      "[3060]\ttrain's multi_logloss: 0.276355\teval's multi_logloss: 0.5598\n",
      "[3070]\ttrain's multi_logloss: 0.275608\teval's multi_logloss: 0.559619\n",
      "[3080]\ttrain's multi_logloss: 0.275521\teval's multi_logloss: 0.559612\n",
      "[3090]\ttrain's multi_logloss: 0.274346\teval's multi_logloss: 0.559254\n",
      "[3100]\ttrain's multi_logloss: 0.273183\teval's multi_logloss: 0.558952\n",
      "[3110]\ttrain's multi_logloss: 0.272049\teval's multi_logloss: 0.558573\n",
      "[3120]\ttrain's multi_logloss: 0.271603\teval's multi_logloss: 0.558449\n",
      "[3130]\ttrain's multi_logloss: 0.271241\teval's multi_logloss: 0.558449\n",
      "[3140]\ttrain's multi_logloss: 0.270134\teval's multi_logloss: 0.558037\n",
      "[3150]\ttrain's multi_logloss: 0.268683\teval's multi_logloss: 0.557531\n",
      "[3160]\ttrain's multi_logloss: 0.268242\teval's multi_logloss: 0.557412\n",
      "[3170]\ttrain's multi_logloss: 0.268162\teval's multi_logloss: 0.557444\n",
      "[3180]\ttrain's multi_logloss: 0.267304\teval's multi_logloss: 0.557214\n",
      "[3190]\ttrain's multi_logloss: 0.266571\teval's multi_logloss: 0.556903\n",
      "[3200]\ttrain's multi_logloss: 0.266442\teval's multi_logloss: 0.556831\n",
      "[3210]\ttrain's multi_logloss: 0.26529\teval's multi_logloss: 0.556441\n",
      "[3220]\ttrain's multi_logloss: 0.264852\teval's multi_logloss: 0.556382\n",
      "[3230]\ttrain's multi_logloss: 0.26422\teval's multi_logloss: 0.556232\n",
      "[3240]\ttrain's multi_logloss: 0.263493\teval's multi_logloss: 0.55602\n",
      "[3250]\ttrain's multi_logloss: 0.262118\teval's multi_logloss: 0.555536\n",
      "[3260]\ttrain's multi_logloss: 0.261133\teval's multi_logloss: 0.555266\n",
      "[3270]\ttrain's multi_logloss: 0.261021\teval's multi_logloss: 0.555302\n",
      "[3280]\ttrain's multi_logloss: 0.259606\teval's multi_logloss: 0.554896\n",
      "[3290]\ttrain's multi_logloss: 0.258867\teval's multi_logloss: 0.55471\n",
      "[3300]\ttrain's multi_logloss: 0.258207\teval's multi_logloss: 0.554598\n",
      "[3310]\ttrain's multi_logloss: 0.257554\teval's multi_logloss: 0.554499\n",
      "[3320]\ttrain's multi_logloss: 0.256795\teval's multi_logloss: 0.554301\n",
      "[3330]\ttrain's multi_logloss: 0.255742\teval's multi_logloss: 0.554108\n",
      "[3340]\ttrain's multi_logloss: 0.253854\teval's multi_logloss: 0.55353\n",
      "[3350]\ttrain's multi_logloss: 0.252536\teval's multi_logloss: 0.553152\n",
      "[3360]\ttrain's multi_logloss: 0.251905\teval's multi_logloss: 0.553027\n",
      "[3370]\ttrain's multi_logloss: 0.25072\teval's multi_logloss: 0.552692\n",
      "[3380]\ttrain's multi_logloss: 0.249531\teval's multi_logloss: 0.552389\n",
      "[3390]\ttrain's multi_logloss: 0.248591\teval's multi_logloss: 0.552197\n",
      "[3400]\ttrain's multi_logloss: 0.247842\teval's multi_logloss: 0.552058\n",
      "[3410]\ttrain's multi_logloss: 0.246979\teval's multi_logloss: 0.551819\n",
      "[3420]\ttrain's multi_logloss: 0.246334\teval's multi_logloss: 0.551664\n",
      "[3430]\ttrain's multi_logloss: 0.245658\teval's multi_logloss: 0.551549\n",
      "[3440]\ttrain's multi_logloss: 0.245487\teval's multi_logloss: 0.551551\n",
      "[3450]\ttrain's multi_logloss: 0.245063\teval's multi_logloss: 0.551416\n",
      "[3460]\ttrain's multi_logloss: 0.244656\teval's multi_logloss: 0.551431\n",
      "[3470]\ttrain's multi_logloss: 0.243964\teval's multi_logloss: 0.551353\n",
      "[3480]\ttrain's multi_logloss: 0.243013\teval's multi_logloss: 0.551161\n",
      "[3490]\ttrain's multi_logloss: 0.242304\teval's multi_logloss: 0.551026\n",
      "[3500]\ttrain's multi_logloss: 0.242176\teval's multi_logloss: 0.551066\n",
      "[3510]\ttrain's multi_logloss: 0.241793\teval's multi_logloss: 0.551003\n",
      "[3520]\ttrain's multi_logloss: 0.240802\teval's multi_logloss: 0.550736\n",
      "[3530]\ttrain's multi_logloss: 0.239855\teval's multi_logloss: 0.55056\n",
      "[3540]\ttrain's multi_logloss: 0.238657\teval's multi_logloss: 0.550205\n",
      "[3550]\ttrain's multi_logloss: 0.237565\teval's multi_logloss: 0.549933\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-d077151e0ad8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgbm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_sets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0md_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'eval'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\anubh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    216\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anubh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1800\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1802\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1803\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1804\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gbm = lgb.train(v,d_train,early_stopping_rounds=30,verbose_eval=10,valid_sets = [d_val,d_train],valid_names = ['eval', 'train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesub(\"sixth\",y_pred,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
