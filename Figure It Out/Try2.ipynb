{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data reading\n",
    "train = pd.read_csv(\"./train/train.csv\")\n",
    "test = pd.read_csv(\"./test/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35950 entries, 0 to 35949\n",
      "Columns: 102 entries, unique_id to targets\n",
      "dtypes: float64(11), int64(91)\n",
      "memory usage: 28.0 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7364 entries, 0 to 7363\n",
      "Columns: 101 entries, unique_id to x_100\n",
      "dtypes: float64(11), int64(90)\n",
      "memory usage: 5.7 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#data cleaning\n",
    "print(train.info())\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>...</th>\n",
       "      <th>x_92</th>\n",
       "      <th>x_93</th>\n",
       "      <th>x_94</th>\n",
       "      <th>x_95</th>\n",
       "      <th>x_96</th>\n",
       "      <th>x_97</th>\n",
       "      <th>x_98</th>\n",
       "      <th>x_99</th>\n",
       "      <th>x_100</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35950.000000</td>\n",
       "      <td>35950.000000</td>\n",
       "      <td>35950.000000</td>\n",
       "      <td>35950.000000</td>\n",
       "      <td>35950.000000</td>\n",
       "      <td>35950.000000</td>\n",
       "      <td>35950.000000</td>\n",
       "      <td>35950.000000</td>\n",
       "      <td>35950.000000</td>\n",
       "      <td>35950.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>35950.000000</td>\n",
       "      <td>35950.000000</td>\n",
       "      <td>35950.000000</td>\n",
       "      <td>35950.000000</td>\n",
       "      <td>35950.000000</td>\n",
       "      <td>35950.000000</td>\n",
       "      <td>35950.000000</td>\n",
       "      <td>35950.000000</td>\n",
       "      <td>35950.000000</td>\n",
       "      <td>35950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17974.500000</td>\n",
       "      <td>0.388428</td>\n",
       "      <td>0.264117</td>\n",
       "      <td>0.902476</td>\n",
       "      <td>0.760862</td>\n",
       "      <td>0.068234</td>\n",
       "      <td>-101.224659</td>\n",
       "      <td>0.198081</td>\n",
       "      <td>0.656273</td>\n",
       "      <td>1.030626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380167</td>\n",
       "      <td>0.126871</td>\n",
       "      <td>0.991290</td>\n",
       "      <td>0.507038</td>\n",
       "      <td>18.892054</td>\n",
       "      <td>2.008901</td>\n",
       "      <td>2.493466</td>\n",
       "      <td>5.990737</td>\n",
       "      <td>1.622118</td>\n",
       "      <td>4.834131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10378.015425</td>\n",
       "      <td>1.578299</td>\n",
       "      <td>1.221808</td>\n",
       "      <td>2.984517</td>\n",
       "      <td>2.662229</td>\n",
       "      <td>0.403661</td>\n",
       "      <td>0.219112</td>\n",
       "      <td>1.052576</td>\n",
       "      <td>2.255469</td>\n",
       "      <td>3.537739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985884</td>\n",
       "      <td>1.190128</td>\n",
       "      <td>3.139378</td>\n",
       "      <td>1.543618</td>\n",
       "      <td>39.184909</td>\n",
       "      <td>1.418585</td>\n",
       "      <td>1.438149</td>\n",
       "      <td>1.543764</td>\n",
       "      <td>2.056319</td>\n",
       "      <td>2.515290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-101.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-12.558415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8987.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-101.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.118049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.252277</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.510907</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17974.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-101.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.489827</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.997520</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>26961.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-101.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.098777</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.728625</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.938141</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>35949.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>-91.250000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>13.009378</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.999978</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>57.168059</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          unique_id           x_1           x_2           x_3           x_4  \\\n",
       "count  35950.000000  35950.000000  35950.000000  35950.000000  35950.000000   \n",
       "mean   17974.500000      0.388428      0.264117      0.902476      0.760862   \n",
       "std    10378.015425      1.578299      1.221808      2.984517      2.662229   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%     8987.250000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    17974.500000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    26961.750000      0.000000      0.000000      0.000000      0.000000   \n",
       "max    35949.000000     56.000000     41.000000     64.000000     67.000000   \n",
       "\n",
       "                x_5           x_6           x_7           x_8           x_9  \\\n",
       "count  35950.000000  35950.000000  35950.000000  35950.000000  35950.000000   \n",
       "mean       0.068234   -101.224659      0.198081      0.656273      1.030626   \n",
       "std        0.403661      0.219112      1.052576      2.255469      3.537739   \n",
       "min        0.000000   -101.250000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000   -101.250000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000   -101.250000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000   -101.250000      0.000000      1.000000      0.000000   \n",
       "max       13.000000    -91.250000     38.000000     76.000000     43.000000   \n",
       "\n",
       "           ...               x_92          x_93          x_94          x_95  \\\n",
       "count      ...       35950.000000  35950.000000  35950.000000  35950.000000   \n",
       "mean       ...           0.380167      0.126871      0.991290      0.507038   \n",
       "std        ...           0.985884      1.190128      3.139378      1.543618   \n",
       "min        ...           0.000000      0.000000    -12.558415      0.000000   \n",
       "25%        ...           0.000000      0.000000     -1.118049      0.000000   \n",
       "50%        ...           0.000000      0.000000      0.995381      0.000000   \n",
       "75%        ...           0.000000      0.000000      3.098777      1.000000   \n",
       "max        ...          19.000000     83.000000     13.009378     83.000000   \n",
       "\n",
       "               x_96          x_97          x_98          x_99         x_100  \\\n",
       "count  35950.000000  35950.000000  35950.000000  35950.000000  35950.000000   \n",
       "mean      18.892054      2.008901      2.493466      5.990737      1.622118   \n",
       "std       39.184909      1.418585      1.438149      1.543764      2.056319   \n",
       "min        0.000000      0.000000      0.000099      0.000000      0.015504   \n",
       "25%        0.000000      1.000000      1.252277      5.000000      0.510907   \n",
       "50%        2.857143      2.000000      2.489827      6.000000      0.997520   \n",
       "75%       20.000000      3.000000      3.728625      7.000000      1.938141   \n",
       "max      830.000000     10.000000      4.999978     10.000000     57.168059   \n",
       "\n",
       "            targets  \n",
       "count  35950.000000  \n",
       "mean       4.834131  \n",
       "std        2.515290  \n",
       "min        1.000000  \n",
       "25%        2.000000  \n",
       "50%        5.000000  \n",
       "75%        7.000000  \n",
       "max        9.000000  \n",
       "\n",
       "[8 rows x 102 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>...</th>\n",
       "      <th>x_91</th>\n",
       "      <th>x_92</th>\n",
       "      <th>x_93</th>\n",
       "      <th>x_94</th>\n",
       "      <th>x_95</th>\n",
       "      <th>x_96</th>\n",
       "      <th>x_97</th>\n",
       "      <th>x_98</th>\n",
       "      <th>x_99</th>\n",
       "      <th>x_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7364.000000</td>\n",
       "      <td>7364.000000</td>\n",
       "      <td>7364.000000</td>\n",
       "      <td>7364.000000</td>\n",
       "      <td>7364.000000</td>\n",
       "      <td>7364.000000</td>\n",
       "      <td>7364.000000</td>\n",
       "      <td>7364.000000</td>\n",
       "      <td>7364.000000</td>\n",
       "      <td>7364.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7364.000000</td>\n",
       "      <td>7364.000000</td>\n",
       "      <td>7364.000000</td>\n",
       "      <td>7364.000000</td>\n",
       "      <td>7364.000000</td>\n",
       "      <td>7364.000000</td>\n",
       "      <td>7364.000000</td>\n",
       "      <td>7364.000000</td>\n",
       "      <td>7364.000000</td>\n",
       "      <td>7364.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3681.500000</td>\n",
       "      <td>0.371130</td>\n",
       "      <td>0.243346</td>\n",
       "      <td>0.869229</td>\n",
       "      <td>0.809343</td>\n",
       "      <td>0.074823</td>\n",
       "      <td>-101.224878</td>\n",
       "      <td>0.183188</td>\n",
       "      <td>0.696225</td>\n",
       "      <td>1.045627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284492</td>\n",
       "      <td>0.381043</td>\n",
       "      <td>0.118007</td>\n",
       "      <td>1.022866</td>\n",
       "      <td>0.499049</td>\n",
       "      <td>19.324063</td>\n",
       "      <td>1.989815</td>\n",
       "      <td>2.498103</td>\n",
       "      <td>5.994432</td>\n",
       "      <td>1.654464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2125.948024</td>\n",
       "      <td>1.287784</td>\n",
       "      <td>1.237181</td>\n",
       "      <td>2.837705</td>\n",
       "      <td>3.169192</td>\n",
       "      <td>0.525045</td>\n",
       "      <td>0.197895</td>\n",
       "      <td>0.877680</td>\n",
       "      <td>2.419348</td>\n",
       "      <td>3.481596</td>\n",
       "      <td>...</td>\n",
       "      <td>2.198952</td>\n",
       "      <td>0.954115</td>\n",
       "      <td>0.922978</td>\n",
       "      <td>3.140919</td>\n",
       "      <td>1.324812</td>\n",
       "      <td>40.695344</td>\n",
       "      <td>1.410475</td>\n",
       "      <td>1.453911</td>\n",
       "      <td>1.537029</td>\n",
       "      <td>2.178077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-101.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10.797879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1840.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-101.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.096295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.235799</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.510797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3681.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-101.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.028369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.496826</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.012594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5522.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-101.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.122527</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.767664</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.990871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7363.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>-96.250000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>14.510391</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>760.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.999356</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>43.679415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         unique_id          x_1          x_2          x_3          x_4  \\\n",
       "count  7364.000000  7364.000000  7364.000000  7364.000000  7364.000000   \n",
       "mean   3681.500000     0.371130     0.243346     0.869229     0.809343   \n",
       "std    2125.948024     1.287784     1.237181     2.837705     3.169192   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%    1840.750000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%    3681.500000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%    5522.250000     0.000000     0.000000     0.000000     0.000000   \n",
       "max    7363.000000    30.000000    39.000000    44.000000    70.000000   \n",
       "\n",
       "               x_5          x_6          x_7          x_8          x_9  \\\n",
       "count  7364.000000  7364.000000  7364.000000  7364.000000  7364.000000   \n",
       "mean      0.074823  -101.224878     0.183188     0.696225     1.045627   \n",
       "std       0.525045     0.197895     0.877680     2.419348     3.481596   \n",
       "min       0.000000  -101.250000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000  -101.250000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000  -101.250000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000  -101.250000     0.000000     1.000000     0.000000   \n",
       "max      19.000000   -96.250000    19.000000    57.000000    32.000000   \n",
       "\n",
       "          ...              x_91         x_92         x_93         x_94  \\\n",
       "count     ...       7364.000000  7364.000000  7364.000000  7364.000000   \n",
       "mean      ...          0.284492     0.381043     0.118007     1.022866   \n",
       "std       ...          2.198952     0.954115     0.922978     3.140919   \n",
       "min       ...          0.000000     0.000000     0.000000   -10.797879   \n",
       "25%       ...          0.000000     0.000000     0.000000    -1.096295   \n",
       "50%       ...          0.000000     0.000000     0.000000     1.028369   \n",
       "75%       ...          0.000000     0.000000     0.000000     3.122527   \n",
       "max       ...         48.000000    12.000000    37.000000    14.510391   \n",
       "\n",
       "              x_95         x_96         x_97         x_98         x_99  \\\n",
       "count  7364.000000  7364.000000  7364.000000  7364.000000  7364.000000   \n",
       "mean      0.499049    19.324063     1.989815     2.498103     5.994432   \n",
       "std       1.324812    40.695344     1.410475     1.453911     1.537029   \n",
       "min       0.000000     0.000000     0.000000     0.000392     1.000000   \n",
       "25%       0.000000     0.000000     1.000000     1.235799     5.000000   \n",
       "50%       0.000000     2.857143     2.000000     2.496826     6.000000   \n",
       "75%       1.000000    20.000000     3.000000     3.767664     7.000000   \n",
       "max      37.000000   760.000000     9.000000     4.999356    10.000000   \n",
       "\n",
       "             x_100  \n",
       "count  7364.000000  \n",
       "mean      1.654464  \n",
       "std       2.178077  \n",
       "min       0.021471  \n",
       "25%       0.510797  \n",
       "50%       1.012594  \n",
       "75%       1.990871  \n",
       "max      43.679415  \n",
       "\n",
       "[8 rows x 101 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if the data has null values or other such type of values of no use\n",
    "train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are no null values in the pandas dataframe\n",
    "#other important cleaning and other steps can be applied which used to explored later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelling direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f for f in test.columns if \"x_\" in f]\n",
    "x = train[features]\n",
    "y = train[\"targets\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"int32\")\n",
    "y_train = y_train.astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.astype(\"int32\")\n",
    "y_pre = model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.770560897872173"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test,y_pre,labels=[1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7534558327714093"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.669659164630506"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre = model2.predict_proba(x_test)\n",
    "log_loss(y_test,y_pre,labels=[1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(train.select_dtypes(include=[\"int64\"]).columns)\n",
    "cols_t = list(test.select_dtypes(include=[\"int64\"]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tr = train[cols] \n",
    "new_te = test[cols_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f for f in new_te.columns if \"x_\" in f]\n",
    "x = new_tr[features]\n",
    "y = new_tr[\"targets\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "x_val,x_test,y_val,y_test = train_test_split(x_test, y_test, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8818163589851284"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test,y_pre,labels=[1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6891695637313918"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre = model2.predict_proba(x_test)\n",
    "log_loss(y_test,y_pre,labels=[1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_clf = CalibratedClassifierCV(model, method=\"sigmoid\", cv=\"prefit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "            cv='prefit', method='sigmoid')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_clf.fit(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sig_clf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7685164360124116"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7879129549594697"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre = model.predict_proba(x_test)\n",
    "log_loss(y_test,y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>...</th>\n",
       "      <th>x_91</th>\n",
       "      <th>x_92</th>\n",
       "      <th>x_93</th>\n",
       "      <th>x_94</th>\n",
       "      <th>x_95</th>\n",
       "      <th>x_96</th>\n",
       "      <th>x_97</th>\n",
       "      <th>x_98</th>\n",
       "      <th>x_99</th>\n",
       "      <th>x_100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>targets</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>...</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9416</td>\n",
       "      <td>9416</td>\n",
       "      <td>9416</td>\n",
       "      <td>9416</td>\n",
       "      <td>9416</td>\n",
       "      <td>9416</td>\n",
       "      <td>9416</td>\n",
       "      <td>9416</td>\n",
       "      <td>9416</td>\n",
       "      <td>9416</td>\n",
       "      <td>...</td>\n",
       "      <td>9416</td>\n",
       "      <td>9416</td>\n",
       "      <td>9416</td>\n",
       "      <td>9416</td>\n",
       "      <td>9416</td>\n",
       "      <td>9416</td>\n",
       "      <td>9416</td>\n",
       "      <td>9416</td>\n",
       "      <td>9416</td>\n",
       "      <td>9416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>...</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1568</td>\n",
       "      <td>1568</td>\n",
       "      <td>1568</td>\n",
       "      <td>1568</td>\n",
       "      <td>1568</td>\n",
       "      <td>1568</td>\n",
       "      <td>1568</td>\n",
       "      <td>1568</td>\n",
       "      <td>1568</td>\n",
       "      <td>1568</td>\n",
       "      <td>...</td>\n",
       "      <td>1568</td>\n",
       "      <td>1568</td>\n",
       "      <td>1568</td>\n",
       "      <td>1568</td>\n",
       "      <td>1568</td>\n",
       "      <td>1568</td>\n",
       "      <td>1568</td>\n",
       "      <td>1568</td>\n",
       "      <td>1568</td>\n",
       "      <td>1568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1593</td>\n",
       "      <td>1593</td>\n",
       "      <td>1593</td>\n",
       "      <td>1593</td>\n",
       "      <td>1593</td>\n",
       "      <td>1593</td>\n",
       "      <td>1593</td>\n",
       "      <td>1593</td>\n",
       "      <td>1593</td>\n",
       "      <td>1593</td>\n",
       "      <td>...</td>\n",
       "      <td>1593</td>\n",
       "      <td>1593</td>\n",
       "      <td>1593</td>\n",
       "      <td>1593</td>\n",
       "      <td>1593</td>\n",
       "      <td>1593</td>\n",
       "      <td>1593</td>\n",
       "      <td>1593</td>\n",
       "      <td>1593</td>\n",
       "      <td>1593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8116</td>\n",
       "      <td>8116</td>\n",
       "      <td>8116</td>\n",
       "      <td>8116</td>\n",
       "      <td>8116</td>\n",
       "      <td>8116</td>\n",
       "      <td>8116</td>\n",
       "      <td>8116</td>\n",
       "      <td>8116</td>\n",
       "      <td>8116</td>\n",
       "      <td>...</td>\n",
       "      <td>8116</td>\n",
       "      <td>8116</td>\n",
       "      <td>8116</td>\n",
       "      <td>8116</td>\n",
       "      <td>8116</td>\n",
       "      <td>8116</td>\n",
       "      <td>8116</td>\n",
       "      <td>8116</td>\n",
       "      <td>8116</td>\n",
       "      <td>8116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "      <td>...</td>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4879</td>\n",
       "      <td>4879</td>\n",
       "      <td>4879</td>\n",
       "      <td>4879</td>\n",
       "      <td>4879</td>\n",
       "      <td>4879</td>\n",
       "      <td>4879</td>\n",
       "      <td>4879</td>\n",
       "      <td>4879</td>\n",
       "      <td>4879</td>\n",
       "      <td>...</td>\n",
       "      <td>4879</td>\n",
       "      <td>4879</td>\n",
       "      <td>4879</td>\n",
       "      <td>4879</td>\n",
       "      <td>4879</td>\n",
       "      <td>4879</td>\n",
       "      <td>4879</td>\n",
       "      <td>4879</td>\n",
       "      <td>4879</td>\n",
       "      <td>4879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "      <td>...</td>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         unique_id   x_1   x_2   x_3   x_4   x_5   x_6   x_7   x_8   x_9  \\\n",
       "targets                                                                    \n",
       "1             1129  1129  1129  1129  1129  1129  1129  1129  1129  1129   \n",
       "2             9416  9416  9416  9416  9416  9416  9416  9416  9416  9416   \n",
       "3             4680  4680  4680  4680  4680  4680  4680  4680  4680  4680   \n",
       "4             1568  1568  1568  1568  1568  1568  1568  1568  1568  1568   \n",
       "5             1593  1593  1593  1593  1593  1593  1593  1593  1593  1593   \n",
       "6             8116  8116  8116  8116  8116  8116  8116  8116  8116  8116   \n",
       "7             1650  1650  1650  1650  1650  1650  1650  1650  1650  1650   \n",
       "8             4879  4879  4879  4879  4879  4879  4879  4879  4879  4879   \n",
       "9             2919  2919  2919  2919  2919  2919  2919  2919  2919  2919   \n",
       "\n",
       "         ...    x_91  x_92  x_93  x_94  x_95  x_96  x_97  x_98  x_99  x_100  \n",
       "targets  ...                                                                 \n",
       "1        ...    1129  1129  1129  1129  1129  1129  1129  1129  1129   1129  \n",
       "2        ...    9416  9416  9416  9416  9416  9416  9416  9416  9416   9416  \n",
       "3        ...    4680  4680  4680  4680  4680  4680  4680  4680  4680   4680  \n",
       "4        ...    1568  1568  1568  1568  1568  1568  1568  1568  1568   1568  \n",
       "5        ...    1593  1593  1593  1593  1593  1593  1593  1593  1593   1593  \n",
       "6        ...    8116  8116  8116  8116  8116  8116  8116  8116  8116   8116  \n",
       "7        ...    1650  1650  1650  1650  1650  1650  1650  1650  1650   1650  \n",
       "8        ...    4879  4879  4879  4879  4879  4879  4879  4879  4879   4879  \n",
       "9        ...    2919  2919  2919  2919  2919  2919  2919  2919  2919   2919  \n",
       "\n",
       "[9 rows x 101 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby([\"targets\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(train.select_dtypes(include=[\"float64\"]).columns)\n",
    "cols_t = list(test.select_dtypes(include=[\"float64\"]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tr = train[cols].astype(\"float32\") \n",
    "new_te = test[cols_t].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f for f in new_te.columns if \"x_\" in f]\n",
    "x = new_tr[features]\n",
    "y = new_tr[\"targets\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "x_val,x_Test,y_val,y_Test = train_test_split(x_test, y_test, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f for f in test.columns if \"x_\" in f]\n",
    "x = train[features]\n",
    "y = train[\"targets\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "x_val,x_Test,y_val,y_Test = train_test_split(x, y, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\anubh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\users\\anubh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99'] ['x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9', 'x_10', 'x_11', 'x_12', 'x_13', 'x_14', 'x_15', 'x_16', 'x_17', 'x_18', 'x_19', 'x_20', 'x_21', 'x_22', 'x_23', 'x_24', 'x_25', 'x_26', 'x_27', 'x_28', 'x_29', 'x_30', 'x_31', 'x_32', 'x_33', 'x_34', 'x_35', 'x_36', 'x_37', 'x_38', 'x_39', 'x_40', 'x_41', 'x_42', 'x_43', 'x_44', 'x_45', 'x_46', 'x_47', 'x_48', 'x_49', 'x_50', 'x_51', 'x_52', 'x_53', 'x_54', 'x_55', 'x_56', 'x_57', 'x_58', 'x_59', 'x_60', 'x_61', 'x_62', 'x_63', 'x_64', 'x_65', 'x_66', 'x_67', 'x_68', 'x_69', 'x_70', 'x_71', 'x_72', 'x_73', 'x_74', 'x_75', 'x_76', 'x_77', 'x_78', 'x_79', 'x_80', 'x_81', 'x_82', 'x_83', 'x_84', 'x_85', 'x_86', 'x_87', 'x_88', 'x_89', 'x_90', 'x_91', 'x_92', 'x_93', 'x_94', 'x_95', 'x_96', 'x_97', 'x_98', 'x_99', 'x_100']\nexpected f3, f11, f0, f92, f98, f16, f81, f14, f25, f20, f73, f57, f83, f47, f54, f72, f75, f94, f45, f12, f38, f42, f84, f2, f7, f63, f80, f74, f6, f35, f51, f55, f64, f69, f28, f19, f33, f77, f90, f97, f8, f31, f41, f60, f70, f56, f58, f86, f53, f43, f76, f40, f15, f96, f65, f85, f5, f1, f93, f23, f95, f21, f32, f78, f68, f79, f89, f99, f67, f66, f36, f30, f50, f44, f27, f82, f59, f46, f61, f87, f22, f4, f24, f91, f49, f26, f10, f13, f48, f52, f18, f88, f34, f62, f37, f71, f29, f9, f39, f17 in input data\ntraining data did not have the following fields: x_81, x_56, x_46, x_13, x_58, x_51, x_33, x_19, x_97, x_20, x_21, x_5, x_10, x_52, x_89, x_71, x_80, x_60, x_35, x_61, x_7, x_70, x_39, x_88, x_75, x_83, x_99, x_4, x_40, x_87, x_95, x_6, x_63, x_18, x_37, x_28, x_11, x_69, x_43, x_8, x_36, x_77, x_53, x_96, x_93, x_59, x_44, x_74, x_66, x_76, x_25, x_1, x_62, x_94, x_100, x_86, x_48, x_26, x_65, x_41, x_16, x_31, x_30, x_50, x_98, x_47, x_90, x_14, x_91, x_38, x_73, x_49, x_68, x_55, x_45, x_67, x_12, x_17, x_22, x_23, x_54, x_9, x_57, x_27, x_3, x_42, x_24, x_79, x_78, x_72, x_32, x_34, x_2, x_64, x_84, x_85, x_29, x_15, x_92, x_82",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-e7c5b0157095>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0my_pre1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_Test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_Test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pre1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anubh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, data, ntree_limit, validate_features)\u001b[0m\n\u001b[0;32m    800\u001b[0m         class_probs = self.get_booster().predict(test_dmatrix,\n\u001b[0;32m    801\u001b[0m                                                  \u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 802\u001b[1;33m                                                  validate_features=validate_features)\n\u001b[0m\u001b[0;32m    803\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"multi:softprob\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mclass_probs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anubh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[0;32m   1216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1218\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anubh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1540\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[1;32m-> 1541\u001b[1;33m                                             data.feature_names))\n\u001b[0m\u001b[0;32m   1542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1543\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99'] ['x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9', 'x_10', 'x_11', 'x_12', 'x_13', 'x_14', 'x_15', 'x_16', 'x_17', 'x_18', 'x_19', 'x_20', 'x_21', 'x_22', 'x_23', 'x_24', 'x_25', 'x_26', 'x_27', 'x_28', 'x_29', 'x_30', 'x_31', 'x_32', 'x_33', 'x_34', 'x_35', 'x_36', 'x_37', 'x_38', 'x_39', 'x_40', 'x_41', 'x_42', 'x_43', 'x_44', 'x_45', 'x_46', 'x_47', 'x_48', 'x_49', 'x_50', 'x_51', 'x_52', 'x_53', 'x_54', 'x_55', 'x_56', 'x_57', 'x_58', 'x_59', 'x_60', 'x_61', 'x_62', 'x_63', 'x_64', 'x_65', 'x_66', 'x_67', 'x_68', 'x_69', 'x_70', 'x_71', 'x_72', 'x_73', 'x_74', 'x_75', 'x_76', 'x_77', 'x_78', 'x_79', 'x_80', 'x_81', 'x_82', 'x_83', 'x_84', 'x_85', 'x_86', 'x_87', 'x_88', 'x_89', 'x_90', 'x_91', 'x_92', 'x_93', 'x_94', 'x_95', 'x_96', 'x_97', 'x_98', 'x_99', 'x_100']\nexpected f3, f11, f0, f92, f98, f16, f81, f14, f25, f20, f73, f57, f83, f47, f54, f72, f75, f94, f45, f12, f38, f42, f84, f2, f7, f63, f80, f74, f6, f35, f51, f55, f64, f69, f28, f19, f33, f77, f90, f97, f8, f31, f41, f60, f70, f56, f58, f86, f53, f43, f76, f40, f15, f96, f65, f85, f5, f1, f93, f23, f95, f21, f32, f78, f68, f79, f89, f99, f67, f66, f36, f30, f50, f44, f27, f82, f59, f46, f61, f87, f22, f4, f24, f91, f49, f26, f10, f13, f48, f52, f18, f88, f34, f62, f37, f71, f29, f9, f39, f17 in input data\ntraining data did not have the following fields: x_81, x_56, x_46, x_13, x_58, x_51, x_33, x_19, x_97, x_20, x_21, x_5, x_10, x_52, x_89, x_71, x_80, x_60, x_35, x_61, x_7, x_70, x_39, x_88, x_75, x_83, x_99, x_4, x_40, x_87, x_95, x_6, x_63, x_18, x_37, x_28, x_11, x_69, x_43, x_8, x_36, x_77, x_53, x_96, x_93, x_59, x_44, x_74, x_66, x_76, x_25, x_1, x_62, x_94, x_100, x_86, x_48, x_26, x_65, x_41, x_16, x_31, x_30, x_50, x_98, x_47, x_90, x_14, x_91, x_38, x_73, x_49, x_68, x_55, x_45, x_67, x_12, x_17, x_22, x_23, x_54, x_9, x_57, x_27, x_3, x_42, x_24, x_79, x_78, x_72, x_32, x_34, x_2, x_64, x_84, x_85, x_29, x_15, x_92, x_82"
     ]
    }
   ],
   "source": [
    "x_train = x_train.as_matrix()\n",
    "y_train = y_train.as_matrix()\n",
    "model2.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\anubh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\users\\anubh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6492035170013709\n"
     ]
    }
   ],
   "source": [
    "x_Test = x_Test.as_matrix()\n",
    "y_Test = y_Test.as_matrix()\n",
    "y_pre1 = model2.predict_proba(x_Test)\n",
    "print(log_loss(y_Test,y_pre1,labels=[1,2,3,4,5,6,7,8,9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'as_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-953d247e2baa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'as_matrix'"
     ]
    }
   ],
   "source": [
    "x_val = x_val.as_matrix()\n",
    "y_val = y_val.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6205301099550644\n"
     ]
    }
   ],
   "source": [
    "sig_clf = CalibratedClassifierCV(model2, method=\"isotonic\", cv=\"prefit\")\n",
    "sig_clf.fit(x_val,y_val)\n",
    "y_pre2 = sig_clf.predict_proba(x_Test)\n",
    "print(log_loss(y_Test,y_pre2,labels=[1,2,3,4,5,6,7,8,9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\anubh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.10, random_state=42)\n",
    "x_train,x_test,y_train,y_test = x_train.as_matrix(),x_test.as_matrix(),y_train.as_matrix(),y_test.as_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6775276347456606\n",
      "0.6029956349698732\n"
     ]
    }
   ],
   "source": [
    "model2.fit(x_train,y_train)\n",
    "y_pre1 = model2.predict_proba(x_test)\n",
    "print(log_loss(y_test,y_pre1,labels=[1,2,3,4,5,6,7,8,9]))\n",
    "sig_clf = CalibratedClassifierCV(model2, method=\"isotonic\", cv=\"prefit\")\n",
    "sig_clf.fit(x_test,y_test)\n",
    "y_pre2 = sig_clf.predict_proba(x_test)\n",
    "print(log_loss(y_test,y_pre2,labels=[1,2,3,4,5,6,7,8,9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\anubh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_f = test[features].as_matrix()\n",
    "y_pre3 = sig_clf.predict_proba(test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7364, 9)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(y_pre3,columns=['proba_1', 'proba_2', 'proba_3', 'proba_4', 'proba_5', 'proba_6', 'proba_7', 'proba_8', 'proba_9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"unique_id\"] = test[\"unique_id\"]\n",
    "columns=[\"unique_id\",'proba_1', 'proba_2', 'proba_3', 'proba_4', 'proba_5', 'proba_6', 'proba_7', 'proba_8', 'proba_9']\n",
    "a = a[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to_csv(\"second_sub.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
